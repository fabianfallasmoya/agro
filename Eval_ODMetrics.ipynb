{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eval_ODMetrics.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1KqqU5qZaOQqjUbxO2jtLMtABEK2H6l1w",
      "authorship_tag": "ABX9TyPKZURfDScw3LqYFKd6wRnS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabianfallasmoya/agro/blob/master/Eval_ODMetrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCI70-xGsRhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a7258dab-741e-403b-da64-15cbf45cc826"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8RnGRewsmpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "outputId": "258d99cb-3bb2-4b01-f66e-4bb32f4818ca"
      },
      "source": [
        "!pip install pycocotools numpy==1.16.0 opencv-python tqdm tensorboard tensorboardX pyyaml webcolors matplotlib\n",
        "!pip install torch==1.4.0\n",
        "!pip install torchvision==0.5.0"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: numpy==1.16.0 in /usr/local/lib/python3.6/dist-packages (1.16.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: webcolors in /usr/local/lib/python3.6/dist-packages (1.11.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (0.29.21)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (50.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.32.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.4.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fInrPTOfxxjn",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the required repositories\n",
        "* https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch\n",
        "\n",
        "* https://github.com/rafaelpadilla/Object-Detection-Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoMPDqDItU0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d5918ed3-7553-4875-ebf5-5be90241a9c5"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "#Download EfficientDet\n",
        "if \"Yet-Another-EfficientDet-Pytorch\" not in os.getcwd():\n",
        "  !git clone --depth 1 https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch\n",
        "else:\n",
        "  !git pull\n",
        "\n",
        "#Download Object Detection Metrics\n",
        "if \"Object-Detection-Metrics\" not in os.getcwd():\n",
        "  !git clone --depth 1 https://github.com/rafaelpadilla/Object-Detection-Metrics\n",
        "else:\n",
        "  !git pull\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Yet-Another-EfficientDet-Pytorch' already exists and is not an empty directory.\n",
            "fatal: destination path 'Object-Detection-Metrics' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUPg5YBkqhol",
        "colab_type": "text"
      },
      "source": [
        "# Executing the Object Detection Metrics, through Rafael's Padilla code\n",
        "\n",
        "### The next cell will be the only one to be changed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN44XpLA05hJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###These lines need to be changed by the user################\n",
        "\n",
        "project = 'apple' #This is the yml project name, also is the class name of the bboxes\n",
        "weightsDir = '/content/drive/My Drive/checkpoints/apple/apple/' #This is the directory where the weights file is located\n",
        "wieghtsFileName = 'efficientdet-d6_epoch60_step3111.pth' #The name of the weights file\n",
        "#The .zip file of the dataset, this dataset is required with the Zylo structure for efficientDet custom datasets\n",
        "datasetpath = '/content/drive/My Drive/pineapple_research/deepFruits_dataset/cocoFormat/apple.zip'\n",
        "#This directory is where the results of the evaluation will be stored\n",
        "dirForGroundTruthAndDetections = '/content/eval'\n",
        "nms_threshold = 0.4\n",
        "coefficient = 6 ## EfficientDet coefficient\n",
        "###########################################################"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdlbcUwGqxEO",
        "colab_type": "text"
      },
      "source": [
        "## Building the groundtruth and detection files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFADHOLduhyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATE yml for project's config\n",
        "with open(\"/content/Yet-Another-EfficientDet-Pytorch/projects/\"+str(project)+\".yml\", \"w+\") as out:\n",
        "    out.write(\"project_name: \"+str(project)+\"\\n\")\n",
        "    out.write(\"train_set: train\\n\")\n",
        "    out.write(\"val_set: test\\n\")\n",
        "    out.write(\"num_gpus: 1\\n\")\n",
        "    out.write(\"mean: [0.485, 0.456, 0.406]\\n\")\n",
        "    out.write(\"std: [0.229, 0.224, 0.225]\\n\")\n",
        "    out.write(\"anchors_scales: '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]'\\n\")\n",
        "    out.write(\"anchors_ratios: '[(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)]'\\n\")\n",
        "    out.write(\"obj_list: ['\"+str(project)+\"']\\n\")\n",
        "    out.write(\"\\n\")\n",
        "    out.write(\"\\n\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyTF8U-BvWMO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd3d3415-590b-41a0-d527-7e1ed22f805a"
      },
      "source": [
        "weightspath = weightsDir+wieghtsFileName \n",
        "! mkdir '/content/Yet-Another-EfficientDet-Pytorch/logs'\n",
        "! mkdir '/content/Yet-Another-EfficientDet-Pytorch/logs/{project}'\n",
        "! cp -r '{weightspath}' '/content/Yet-Another-EfficientDet-Pytorch/logs/{project}/'\n",
        "\n",
        "! mkdir '/content/Yet-Another-EfficientDet-Pytorch/datasets'\n",
        "! unzip '{datasetpath}' -d '/content/Yet-Another-EfficientDet-Pytorch/datasets/'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/Yet-Another-EfficientDet-Pytorch/logs’: File exists\n",
            "mkdir: cannot create directory ‘/content/Yet-Another-EfficientDet-Pytorch/logs/apple’: File exists\n",
            "mkdir: cannot create directory ‘/content/Yet-Another-EfficientDet-Pytorch/datasets’: File exists\n",
            "Archive:  /content/drive/My Drive/pineapple_research/deepFruits_dataset/cocoFormat/apple.zip\n",
            "replace /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/annotations/instances_test.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/annotations/instances_test.json  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/annotations/instances_train.json  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/1237_png.rf.b84f9ebc5046e7c0746f8c8098d84529.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/Apple_Tree-106_png.rf.64b48008a499effd3c4834c246a55de3.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/Apple-Anna-Fruit-and-leaves1_png.rf.b70c33eb586ecafcdca7cc1e20b0e941.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/apples-on-tree_png.rf.4c974f4d57e1fe05f23ceafbdaede706.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/Apple-tree-Alamy-large_png.rf.9f10f050c748fcedc08d84f8faef39ca.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/apple-tree-lg_png.rf.9e10ceef1f97f02f0877dea48a11a4ab.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/gala-apples_png.rf.0517bdc9d2f061d3a6639ae4a0f63f9b.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/Golden_png.rf.61408ab0cb75de92b61d353665235c34.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/maxresdefault_png.rf.03d393564e67a99589df60b6bd705be7.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/productsquare_red-chief_20151008230618_png.rf.5eb51dea6592881f4eb0aa5aba6e9614.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/ranetka_ermolaeva_png.rf.aaf641697bac5f30e6cb8f6f71a6e51c.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/VinhHo-TanManChuyenDiMinnesota-35_png.rf.b895ead340226fffc6d1d09dd17fda6a.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/test/Winesap-Apple-Tree-450w_png.rf.0255f8771ec56a1b839cda2d87be4c7a.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/1_png.rf.fe104db24e2244334d1d87b72501ad55.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/2010-12-07-05-26-38_1291641998_png.rf.2f7817c8d1628f673aa465024b1fc56f.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/244sub_travel_9_png.rf.aec85cbdc715cb40552a8d10f42b6077.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/2844-960x960_png.rf.bebbf216e1c345fef72711545491960f.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/2979_png.rf.828441d6be81de2b4d80db8956bdfdef.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/45677_png.rf.a6c67d1ef2dd0fd4cc65b8b02e3b8657.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/47_2_png.rf.773ecded50073896f6d7fc7970f129d9.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/6104689538_2581252714_b_png.rf.754688b4345afafb59c24199d40f41f6.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/74477A_png.rf.8c72b0dc0e1a2750d66f06200acc7a46.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/7807503254_9d54ae414f_z_png.rf.f421fb73b9844452cec7c36f0a1a92c0.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/860929755-little-switzerland-ripe-condition-apple-tree-apple-fruit_png.rf.99ddd67bcf09aacf3dfc268cc7a11ed8.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/905496294_885_png.rf.aec861f56c9acf15d9e10067b48699f1.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/anna-apple_png.rf.b6cfcee9d7101a9e5199ad37e0da5f51.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/APPLE_png.rf.33164147267642b80ae7f4f021ee9b4f.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/Apple_tree_Alamy_3400740b_png.rf.87bce7463e03d48574036c8714a0ae15.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/apple_tree_green_188c6l8-188c6ne_png.rf.df563fb631a15062192b8223c7208ddd.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/applelele_png.rf.4f4a38951b3b9784f42e6a9fe89160ff.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/apples-photos--big-green-apples-on-tree--close-up-94309_png.rf.437e1b49e14d596e8a53b1e9491037c4.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/apple-tree_png.rf.942666eacbf8ec1e01bc718e980f81e3.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/apple-tree-1_png.rf.9e10ceef1f97f02f0877dea48a11a4ab.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/apple-tree-1262424_960_720_png.rf.cd582cc59f4b6015c599577f7760e133.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/Apple-Tree-With-Green-Apples_png.rf.e77dfc0b417eefad11f3c653f43d9d5f.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/bevans3_png.rf.d313dda3d0e9050a050379b576c4590c.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/Bonsai-tree_png.rf.c81278a4f4c2ae92c90b74006b37279c.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/CroppedImage910400-golden-delicious-apples-495-400_png.rf.0b528327fda31b6a31664f2461e9fc86.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/Delikates_apple_cultivar_png.rf.0893bed3da02fd74e6f2641890f6cd93.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/E12812977-14_png.rf.34d435a618a697ff903d996079f0e630.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/easy-apple-recipes-for-fall_png.rf.503f9620b3e6dad1c6cb490701708e91.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/Fresh-ripe-apples-on-tree-in-Kasauli_png.rf.7df8c0cf0999be998caed6f6d0957ba8.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/fruit_apple_apple-tree_wallpaper_apple_07_png.rf.bf00bd9bf32317ee5293b50475e14a70.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/fruit_apple_apple-tree_wallpaper_ea60142_png.rf.b49d966282cee94d50614052358fa44d.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/Gala-2015-2-1024x768_png.rf.04aea8852f67b809dcdc696396b93b7d.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/Golden-Delicious-Apple-1-1024x685_png.rf.9c2e643de49ca5d5cca6dff6cc1be0f5.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/golden-delicious-apples-495-400_png.rf.0cc8300fb0e46207795497da3a6091c9.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/granny-smith-apples_png.rf.acaaf4ec45f8440c10f43daec2013bdb.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/green_app_png.rf.b06bafd8c21e4dfc1647944dcae3a548.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/green-apple-tree_png.rf.a9280e943248c5125d4ffc07d8d8dacd.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/IMG_0768_png.rf.cccf4af4da06aa1573e4f0ef41eadb95.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/IMG_1951_png.rf.eecd153c583636dd92b8b1cbd14fef19.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/img_2017_png.rf.00c7863054bc550d21736ca803ca61b3.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/img_6237_png.rf.a385777e1e621713cb3691bc44bfc8fe.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/img_6479-001-e1378168705770_png.rf.229a6650a4be4c9a2b2af9a32cb2a4ea.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/Mcintosh_Apple_Tree_450_3_png.rf.a33f5d476df9d8c971d29e1ddbb9b2cd.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/PinkLady-apple-tree-23_png.rf.223ea517b50520c085e658f5682faaef.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/prune_my_wild_apple_trees_png.rf.54cd054a8a36b8f61e681253b1ce0ff8.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/static1_png.rf.afde95a67641a5743d21daa57a901874.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/stockvault-green-apples100101_png.rf.96f8bb8bc25c58f872b5f4d0f7307106.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/sturmer-pippins_png.rf.b6ef0eefd6e8ed1cd2bd5c78503fa1ec.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/tc_0048-1_png.rf.f8432876618fc01b6db4495ef48c04a7.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/the-apple-tree-thumb_png.rf.3fca15c0edeed19c270c3f42411c3d99.jpg  \n",
            "  inflating: /content/Yet-Another-EfficientDet-Pytorch/datasets/apple/train/urban-apple-tree_png.rf.1f3378d3cc21f26e8d06d57420239d58.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi1ERbvKlVL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/')\n",
        "os.chdir('Yet-Another-EfficientDet-Pytorch')\n",
        "import cv2\n",
        "import torch\n",
        "import os\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from backbone import EfficientDetBackbone\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import yaml\n",
        "import json\n",
        "\n",
        "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
        "from utils.utils import preprocess, invert_affine, postprocess\n",
        "\n",
        "def getImageDetections(imagePath,weights,nms_threshold,confidenceParam,coefficient):\n",
        "  compound_coef = coefficient\n",
        "  force_input_size = None  # set None to use default size\n",
        "  img_path  = imagePath\n",
        "\n",
        "  threshold = confidenceParam\n",
        "  iou_threshold = nms_threshold\n",
        "\n",
        "  use_cuda = True\n",
        "  use_float16 = False\n",
        "  cudnn.fastest = True\n",
        "  cudnn.benchmark = True\n",
        "\n",
        "  obj_list = ['pineapple']\n",
        "\n",
        "  # tf bilinear interpolation is different from any other's, just make do\n",
        "  input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
        "  input_size = input_sizes[compound_coef] if force_input_size is None else force_input_size\n",
        "  ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)\n",
        "\n",
        "  if use_cuda:\n",
        "      x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n",
        "  else:\n",
        "      x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)\n",
        "\n",
        "  x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)\n",
        "\n",
        "  model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
        "\n",
        "                              # replace this part with your project's anchor config\n",
        "                              ratios=[(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)],\n",
        "                              scales=[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
        "\n",
        "  model.load_state_dict(torch.load('/content/Yet-Another-EfficientDet-Pytorch/logs/apple/'+weights))\n",
        "  model.requires_grad_(False)\n",
        "  model.eval()\n",
        "\n",
        "  if use_cuda:\n",
        "      model = model.cuda()\n",
        "  if use_float16:\n",
        "      model = model.half()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      features, regression, classification, anchors = model(x)\n",
        "\n",
        "      regressBoxes = BBoxTransform()\n",
        "      clipBoxes = ClipBoxes()\n",
        "\n",
        "      out = postprocess(x,\n",
        "                        anchors, regression, classification,\n",
        "                        regressBoxes, clipBoxes,\n",
        "                        threshold, iou_threshold)\n",
        "\n",
        "  out = invert_affine(framed_metas, out)\n",
        "\n",
        "  from PIL import Image\n",
        "  import PIL\n",
        "      \n",
        "  for i in range(len(ori_imgs)):\n",
        "      if len(out[i]['rois']) == 0:\n",
        "          continue\n",
        "      detectionsList = []\n",
        "      for j in range(len(out[i]['rois'])):\n",
        "          (x1, y1, x2, y2) = out[i]['rois'][j].astype(np.int)\n",
        "          detectionsList.append((float(out[i]['scores'][j]),x1, y1, x2, y2))\n",
        "      return detectionsList\n",
        "os.chdir('/content/')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htQtSk9jFXzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "98f3ea15-0f0a-4242-b85e-392de41c1258"
      },
      "source": [
        "! mkdir '{dirForGroundTruthAndDetections}/{project}'\n",
        "! mkdir '{dirForGroundTruthAndDetections}/{project}/groundtruths'\n",
        "! mkdir '{dirForGroundTruthAndDetections}/{project}/detections'\n",
        "! mkdir '{dirForGroundTruthAndDetections}/{project}/results'"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/eval/apple’: File exists\n",
            "mkdir: cannot create directory ‘/content/eval/apple/groundtruths’: File exists\n",
            "mkdir: cannot create directory ‘/content/eval/apple/detections’: File exists\n",
            "mkdir: cannot create directory ‘/content/eval/apple/results’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gUa5ZFeo7DB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "def generateFiles(confidenceParam):\n",
        "  params = yaml.safe_load(open(f'/content/Yet-Another-EfficientDet-Pytorch/projects/{project}'+'.yml'))\n",
        "  evaluationfolder = params['val_set']\n",
        "  ##### Let´s create the Ground Truth files to evaluate them with the Object Detection Metrics\n",
        "  dirGroundTruthPath = dirForGroundTruthAndDetections+'/'+project+'/groundtruths/'\n",
        "  dirDetectionsPath = dirForGroundTruthAndDetections+'/'+project+'/detections/'\n",
        "  with open('/content/Yet-Another-EfficientDet-Pytorch/datasets/apple/annotations/instances_'+str(evaluationfolder)+'.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  annotationsDataframe = pd.DataFrame.from_records(data['annotations'])\n",
        "  imagesDataframe = pd.DataFrame.from_records(data['images'])\n",
        "\n",
        "  qtyGroundTruthDets = 0\n",
        "  qtyPredictedDets = 0\n",
        "  for index,image in imagesDataframe.iterrows():\n",
        "    imageName = image['file_name'][0:len(image['file_name'])-4]\n",
        "\n",
        "    fileGroundTruth = open(dirGroundTruthPath+imageName+\".txt\",\"w\")\n",
        "    fileDetections = open(dirDetectionsPath+imageName+\".txt\",\"w\")\n",
        "\n",
        "    imageId = image['id']\n",
        "    for ind,row in annotationsDataframe.loc[annotationsDataframe['image_id'] == imageId].iterrows():\n",
        "      left = int(row['bbox'][0]) \n",
        "      top = int(row['bbox'][1])\n",
        "      w = int(row['bbox'][2])\n",
        "      h = int(row['bbox'][3])\n",
        "      right = left + w\n",
        "      bottom = top + h\n",
        "      #<class_name> <left> <top> <right> <bottom>\n",
        "\n",
        "      fileGroundTruth.write(project+\" \"+str(left)+\" \"+str(top)+\" \"+str(right)+\" \"+str(bottom)+\"\\n\")\n",
        "      qtyGroundTruthDets = qtyGroundTruthDets + 1\n",
        "    \n",
        "    fileGroundTruth.close()\n",
        "\n",
        "    ##### Let´s create the detections files to evaluate them with the Object Detection Metrics\n",
        "    \n",
        "    defaultDatasetPath = '/content/Yet-Another-EfficientDet-Pytorch/datasets/'+project+'/'+evaluationfolder+'/'\n",
        "    image_detections = getImageDetections(defaultDatasetPath+image['file_name'],wieghtsFileName,nms_threshold,confidenceParam,coefficient)\n",
        "    for confidenceScore,xd1,yd1,xd2,yd2 in image_detections:\n",
        "      fileDetections.write(project+\" \"+str(confidenceScore)+\" \"+str(xd1)+\" \"+str(yd1)+\" \"+str(xd2)+\" \"+str(yd2)+\"\\n\")\n",
        "      qtyPredictedDets = qtyPredictedDets + 1\n",
        "    fileDetections.close()\n",
        "  return (qtyGroundTruthDets,qtyPredictedDets)  "
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PbSa0NwrfNC",
        "colab_type": "text"
      },
      "source": [
        "## Methods to run the evaluation over the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIJzRgcm07o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateResults():\n",
        "  ! python /content/Object-Detection-Metrics/pascalvoc.py -gt {dirForGroundTruthAndDetections}/{project}/groundtruths/ -det {dirForGroundTruthAndDetections}/{project}/detections/ -t {nms_threshold} -gtformat xyrb -detformat xyrb -sp {dirForGroundTruthAndDetections}/{project}/results\n",
        "\n",
        "def collectRsultsFromFiles(): \n",
        "  with open(dirForGroundTruthAndDetections+'/'+project+'/results/results.txt',\"r\") as file1:\n",
        "          FileasList = file1.readlines()\n",
        "\n",
        "  precision = FileasList[8].split()[len(FileasList[8].split())-1]\n",
        "  recall = FileasList[9].split()[len(FileasList[9].split())-1]\n",
        "  precision = float(precision[1:len(precision)-2])\n",
        "  recall = float(recall[1:len(recall)-2])\n",
        "  f1Score = 2*((precision*recall)/(precision+recall))\n",
        "  \n",
        "  return (FileasList[6].split()[1],FileasList[7].split()[1],precision,recall,f1Score)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbBRvdgkrorD",
        "colab_type": "text"
      },
      "source": [
        "## Showing the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS8s5rNF5YZe",
        "colab_type": "text"
      },
      "source": [
        "### Showing results with a single confidence score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHNySMKf4lZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "b7890abc-74c3-4cb6-cad3-1ec015adb253"
      },
      "source": [
        "groundTruth, detected = generateFiles(0.5)\n",
        "generateResults()\n",
        "\n",
        "dataset,ap,precision,recall,f1Score = collectRsultsFromFiles()\n",
        "print('##############################################')\n",
        "print('Result over the dataset: '+ dataset)\n",
        "print('Quantity of ground truth boundig boxes: '+str(groundTruth))\n",
        "print('Quantity of predicted boundig boxes: '+str(detected))\n",
        "print('The average precision is (AP): '+ap)\n",
        "print('Precision: '+str(precision))\n",
        "print('Recall: '+str(recall))\n",
        "print('F1 Score: '+str(f1Score))\n",
        "prcurveImg = cv2.imread(dirForGroundTruthAndDetections+'/'+project+'/results/'+project+'.png')\n",
        "plt.imshow(prcurveImg)\n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folder /content/eval/apple/results already exists and may contain important results.\n",
            "\n",
            "Enter 'Y' to continue. WARNING: THIS WILL REMOVE ALL THE CONTENTS OF THE FOLDER!\n",
            "Or enter 'N' to abort and choose another folder to save the results.\n",
            "y\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 84.76% (apple)\n",
            "mAP: 84.76%\n",
            "##############################################\n",
            "Result over the dataset: apple\n",
            "Quantity of ground truth boundig boxes: 65\n",
            "Quantity of predicted boundig boxes: 67\n",
            "The average precision is (AP): 84.76%\n",
            "Precision: 0.87\n",
            "Recall: 0.89\n",
            "F1 Score: 0.8798863636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHbZ7RRM6BGm",
        "colab_type": "text"
      },
      "source": [
        "### Showing results with a multiple confidence score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV2iS0fW6J8N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52bf6e74-1312-4849-e712-de682a17c058"
      },
      "source": [
        "confidence_threshold = 0.05\n",
        "hop = 0.05\n",
        "import csv\n",
        "with open(f'{dirForGroundTruthAndDetections}/{project}/{project}_results_d{coefficient}.csv', \"w\") as myfile:\n",
        "      my_writer = csv.writer(myfile, delimiter=',', quotechar='\"')\n",
        "      my_writer.writerow([\"num_detections\", \"nms_threshold\", \"confidence_threshold\", \"average_precision\", \"precision\", \"recall\", \"f1_score\"])\n",
        "\n",
        "while confidence_threshold < 1:\n",
        "  ! rm -r {dirForGroundTruthAndDetections}/{project}/results\n",
        "  ! mkdir '{dirForGroundTruthAndDetections}/{project}/results'\n",
        "  groundTruth, detected = generateFiles(confidence_threshold)\n",
        "  generateResults()\n",
        "  dataset,ap,precision,recall,f1Score = collectRsultsFromFiles()\n",
        "  \n",
        "  ##Aqui hay que guar los valores en el CSV\n",
        "  with open(f'{dirForGroundTruthAndDetections}/{project}/{project}_results_d{coefficient}.csv', \"a\") as myfile:\n",
        "            my_writer = csv.writer(myfile, delimiter=',', quotechar='\"')\n",
        "            my_writer.writerow([detected, nms_threshold, confidence_threshold,ap, precision,recall,f1Score])\n",
        "\n",
        "  confidence_threshold = round(confidence_threshold + hop,2) "
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 88.75% (apple)\n",
            "mAP: 88.75%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 88.38% (apple)\n",
            "mAP: 88.38%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 86.80% (apple)\n",
            "mAP: 86.80%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 86.04% (apple)\n",
            "mAP: 86.04%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 86.04% (apple)\n",
            "mAP: 86.04%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 86.04% (apple)\n",
            "mAP: 86.04%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 84.76% (apple)\n",
            "mAP: 84.76%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 84.76% (apple)\n",
            "mAP: 84.76%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 84.76% (apple)\n",
            "mAP: 84.76%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 84.76% (apple)\n",
            "mAP: 84.76%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 82.05% (apple)\n",
            "mAP: 82.05%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 82.05% (apple)\n",
            "mAP: 82.05%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 82.05% (apple)\n",
            "mAP: 82.05%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 82.05% (apple)\n",
            "mAP: 82.05%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 82.05% (apple)\n",
            "mAP: 82.05%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 82.05% (apple)\n",
            "mAP: 82.05%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 82.05% (apple)\n",
            "mAP: 82.05%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 77.88% (apple)\n",
            "mAP: 77.88%\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "AP: 70.86% (apple)\n",
            "mAP: 70.86%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}